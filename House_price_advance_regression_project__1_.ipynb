{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House price advance_regression_project _1 .ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O6LWkA5X6Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgi8jdUVud3D",
        "colab_type": "text"
      },
      "source": [
        "*description of the columns**\n",
        "\n",
        "SalePrice - the property's sale price in dollars. This is the target variable \n",
        "\n",
        "that you're trying to predict.\n",
        "\n",
        "MSSubClass: The building class\n",
        "\n",
        "MSZoning: The general zoning classification\n",
        "\n",
        "LotFrontage: Linear feet of street connected to property\n",
        "\n",
        "LotArea: Lot size in square feet\n",
        "\n",
        "Street: Type of road access\n",
        "\n",
        "Alley: Type of alley access\n",
        "\n",
        "LotShape: General shape of property\n",
        "\n",
        "LandContour: Flatness of the property\n",
        "\n",
        "Utilities: Type of utilities available\n",
        "\n",
        "LotConfig: Lot configuration\n",
        "\n",
        "LandSlope: Slope of property\n",
        "\n",
        "Neighborhood: Physical locations within Ames city limits\n",
        "\n",
        "Condition1: Proximity to main road or railroad\n",
        "\n",
        "Condition2: Proximity to main road or railroad (if a second is present)\n",
        "\n",
        "BldgType: Type of dwelling\n",
        "\n",
        "HouseStyle: Style of dwelling\n",
        "\n",
        "OverallQual: Overall material and finish quality\n",
        "\n",
        "OverallCond: Overall condition rating\n",
        "\n",
        "YearBuilt: Original construction date\n",
        "\n",
        "YearRemodAdd: Remodel date\n",
        "\n",
        "RoofStyle: Type of roof\n",
        "RoofMatl: Roof material\n",
        "\n",
        "Exterior1st: Exterior covering on house\n",
        "\n",
        "Exterior2nd: Exterior covering on house (if more than one material)\n",
        "\n",
        "MasVnrType: Masonry veneer type\n",
        "\n",
        "MasVnrArea: Masonry veneer area in square feet\n",
        "\n",
        "ExterQual: Exterior material quality\n",
        "\n",
        "ExterCond: Present condition of the material on the exterior\n",
        "\n",
        "Foundation: Type of foundation\n",
        "\n",
        "BsmtQual: Height of the basement\n",
        "\n",
        "BsmtCond: General condition of the basement\n",
        "\n",
        "BsmtExposure: Walkout or garden level basement walls\n",
        "\n",
        "BsmtFinType1: Quality of basement finished area\n",
        "\n",
        "BsmtFinSF1: Type 1 finished square feet\n",
        "\n",
        "BsmtFinType2: Quality of second finished area (if present)\n",
        "\n",
        "BsmtFinSF2: Type 2 finished square feet\n",
        "\n",
        "BsmtUnfSF: Unfinished square feet of basement area\n",
        "\n",
        "TotalBsmtSF: Total square feet of basement area\n",
        "\n",
        "Heating: Type of heating\n",
        "\n",
        "HeatingQC: Heating quality and condition\n",
        "\n",
        "CentralAir: Central air conditioning\n",
        "\n",
        "Electrical: Electrical system\n",
        "\n",
        "1stFlrSF: First Floor square feet\n",
        "\n",
        "2ndFlrSF: Second floor square feet\n",
        "\n",
        "LowQualFinSF: Low quality finished square feet (all floors)\n",
        "\n",
        "GrLivArea: Above grade (ground) living area square feet\n",
        "\n",
        "BsmtFullBath: Basement full bathrooms\n",
        "\n",
        "BsmtHalfBath: Basement half bathrooms\n",
        "\n",
        "FullBath: Full bathrooms above grade\n",
        "\n",
        "HalfBath: Half baths above grade\n",
        "\n",
        "Bedroom: Number of bedrooms above basement level\n",
        "\n",
        "Kitchen: Number of kitchens\n",
        "\n",
        "KitchenQual: Kitchen quality\n",
        "TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
        "\n",
        "Functional: Home functionality rating\n",
        "\n",
        "Fireplaces: Number of fireplaces\n",
        "\n",
        "FireplaceQu: Fireplace quality\n",
        "\n",
        "GarageType: Garage location\n",
        "\n",
        "GarageYrBlt: Year garage was built\n",
        "\n",
        "GarageFinish: Interior finish of the garage\n",
        "\n",
        "GarageCars: Size of garage in car capacity\n",
        "\n",
        "GarageArea: Size of garage in square feet\n",
        "\n",
        "GarageQual: Garage quality\n",
        "\n",
        "GarageCond: Garage condition\n",
        "\n",
        "PavedDrive: Paved driveway\n",
        "\n",
        "WoodDeckSF: Wood deck area in square feet\n",
        "\n",
        "OpenPorchSF: Open porch area in square feet\n",
        "\n",
        "EnclosedPorch: Enclosed porch area in square feet\n",
        "\n",
        "3SsnPorch: Three season porch area in square feet\n",
        "\n",
        "ScreenPorch: Screen porch area in square feet\n",
        "\n",
        "PoolArea: Pool area in square feet\n",
        "\n",
        "PoolQC: Pool quality\n",
        "\n",
        "Fence: Fence quality\n",
        "\n",
        "MiscFeature: Miscellaneous feature not covered in other categories\n",
        "\n",
        "MiscVal: $Value of miscellaneous feature\n",
        "\n",
        "MoSold: Month Sold\n",
        "\n",
        "YrSold: Year Sold\n",
        "\n",
        "SaleType: Type of sale\n",
        "\n",
        "***SaleCondition: Condition of sale***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULAmUuI7X759",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIolXobsZAdY",
        "colab_type": "text"
      },
      "source": [
        " **READ THE TRAIN FILE OF HOUSE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTtrB_KlY9sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/House Prices Advanced Regression Techniques/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CW1X7UpZr-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzTmFTlHwu7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qs-2KpxZ6jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN9OdPrSVykR",
        "colab_type": "text"
      },
      "source": [
        "*Here we gonna find the missing value percentage*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTmw1o9ladyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total=df_train.isnull().sum().sort_values(ascending=False)\n",
        "percentage=(df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
        "missing_data=pd.concat([total,percentage],axis=1,keys=['total','percentage'])\n",
        "missing_data.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSzOMkI9hKON",
        "colab_type": "text"
      },
      "source": [
        "**I THINK NONE THE VARIABLE ARE IMPORANT FOR PREDICT THE SALE PRICE SO ITS BETTER TO DELETE THESE VARIABLE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB2HjzgugZY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train.drop((missing_data[missing_data['total'] > 1]).index,1)\n",
        "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTbEmjVUiBgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total=df_train.isnull().sum().sort_values(ascending=False)\n",
        "percentage=(df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
        "missing_data=pd.concat([total,percentage],axis=1,keys=['total','percentage'])\n",
        "missing_data.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpPVIXIhuQ94",
        "colab_type": "text"
      },
      "source": [
        "**Analysing the sale price**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "54452e23-f4d3-919f-c734-80a35dc9ae08",
        "_execution_state": "idle",
        "_uuid": "5c15e1bd10b8e71c0b1d62bdb260882585a35579",
        "id": "g_FnYzyNXZI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#descriptive statistics summary\n",
        "df_train['SalePrice'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMkWNWczwBBM",
        "colab_type": "text"
      },
      "source": [
        "Very well... It seems that your minimum price is larger than zero. Excellent! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "6bbea362-77b6-5385-f0a8-fb53afd088b7",
        "_execution_state": "idle",
        "_uuid": "2f78c77caa7290298138caf167672e62d3bc5a67",
        "id": "5UdC353KXZI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#histogram\n",
        "sns.distplot(df_train['SalePrice']);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw0w4QQFwUH8",
        "colab_type": "text"
      },
      "source": [
        "Here i see some\n",
        "\n",
        "**Deviate from the normal distribution.**\n",
        "\n",
        "**Have appreciable positive skewness.**\n",
        "\n",
        "**Show peakedness.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "36766737-f1a3-fe40-dbec-63c31be4d5e0",
        "_execution_state": "idle",
        "_uuid": "2cb253768dcd75b9a450ee264626ce69c808096a",
        "id": "RXUhcsNjXZI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#skewness and kurtosis\n",
        "print(\"Skewness: %f\" % df_train['SalePrice'].skew())\n",
        "print(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAlwOIp0w46E",
        "colab_type": "text"
      },
      "source": [
        "i think some what we see it again haha!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "db040973-0adc-e126-e657-1d8934b5a5c8",
        "_execution_state": "idle",
        "_uuid": "91160363898f5caeee965a1aa81eb3abb7dcd760",
        "id": "w_wG3GoPXZJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scatter plot grlivarea/saleprice\n",
        "var = 'GrLivArea'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmFBS3L5xF3d",
        "colab_type": "text"
      },
      "source": [
        "Hmmm... It seems that 'SalePrice' and 'GrLivArea' are really old friends, with a linear relationship."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "353def35-0f26-998d-b9a4-7356f95e80ad",
        "_execution_state": "idle",
        "_uuid": "3ac3db51311338fcdc16014a7c506cf3d5315af7",
        "id": "-usieO6UXZJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scatter plot totalbsmtsf/saleprice\n",
        "var = 'TotalBsmtSF'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kPjAffQxQWK",
        "colab_type": "text"
      },
      "source": [
        "'TotalBsmtSF' is also a great friend of 'SalePrice' but this seems a much more emotional relationship! Everything is ok and suddenly, in a strong linear (exponential?) reaction, everything changes. Moreover, it's clear that sometimes 'TotalBsmtSF' closes in itself and gives zero credit to 'SalePrice'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "26d0fddc-cb09-af7d-9f03-a07233fa6c9e",
        "_execution_state": "idle",
        "_uuid": "e2b7aaccc3486a74a09996289a833ffb6acd0764",
        "id": "a966rKKdXZJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#box plot overallqual/saleprice\n",
        "var = 'OverallQual'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "f, ax = plt.subplots(figsize=(8, 6))\n",
        "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
        "fig.axis(ymin=0, ymax=800000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "590da500-3e48-7059-4f0b-1ef1801dd1db",
        "_execution_state": "idle",
        "_uuid": "a78c64aeed1e48aa453ae4b7deef172cb2060b39",
        "id": "wNoo1cjQXZJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var = 'YearBuilt'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "f, ax = plt.subplots(figsize=(16, 8))\n",
        "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
        "fig.axis(ymin=0, ymax=800000);\n",
        "plt.xticks(rotation=90);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCvRFdUFxdJi",
        "colab_type": "text"
      },
      "source": [
        "Although it's not a strong tendency, I'd say that 'SalePrice' is more prone to spend more money in new stuff than in old relics.\n",
        "\n",
        "Note: we don't know if 'SalePrice' is in constant prices. Constant prices try to remove the effect of inflation. If 'SalePrice' is not in constant prices, it should be, so than prices are comparable over the years."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhqNdKpGxoF6",
        "colab_type": "text"
      },
      "source": [
        "In summary\n",
        "Stories aside, we can conclude that:\n",
        "\n",
        "'GrLivArea' and 'TotalBsmtSF' seem to be linearly related with 'SalePrice'. Both relationships are positive, which means that as one variable increases, the other also increases. In the case of 'TotalBsmtSF', we can see that the slope of the linear relationship is particularly high.\n",
        "'OverallQual' and 'YearBuilt' also seem to be related with 'SalePrice'. The relationship seems to be stronger in the case of 'OverallQual', where the box plot shows how sales prices increase with the overall quality.\n",
        "We just analysed four variables, but there are many other that we should analyse. The trick here seems to be the choice of the right features (feature selection) and not the definition of complex relationships between them (feature engineering).\n",
        "\n",
        "That said, let's separate the wheat from the chaff."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "4eb7a6ef-adf5-6abf-947d-c95afdc477b8",
        "_execution_state": "idle",
        "_uuid": "5dfee22210f5a126ea34ca6475bb4f365d41317b",
        "id": "nrxWGEXQXZJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#correlation matrix\n",
        "corrmat = df_train.corr()\n",
        "f, ax = plt.subplots(figsize=(15, 10))\n",
        "sns.heatmap(corrmat, vmax=.8, square=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tud-ZGa0x8E_",
        "colab_type": "text"
      },
      "source": [
        "At first sight, there are two red colored squares that get my attention. The first one refers to the 'TotalBsmtSF' and '1stFlrSF' variables, and the second one refers to the 'GarageX' variables. Both cases show how significant the correlation is between these variables. Actually, this correlation is so strong that it can indicate a situation of multicollinearity. If we think about these variables, we can conclude that they give almost the same information so multicollinearity really occurs. Heatmaps are great to detect this kind of situations and in problems dominated by feature selection, like ours, they are an essential tool.\n",
        "\n",
        "Another thing that got my attention was the 'SalePrice' correlations. We can see our well-known 'GrLivArea', 'TotalBsmtSF', and 'OverallQual'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "bc33db9e-9ee3-6cfe-7643-a2aff5a9234d",
        "_execution_state": "idle",
        "_uuid": "a6ee47c540ce9f3f1d2af6efe0b030e76e3a3f7f",
        "id": "TE8JoeA7XZJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saleprice correlation matrix\n",
        "k = 10 #number of variables for heatmap\n",
        "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
        "cm = np.corrcoef(df_train[cols].values.T)\n",
        "sns.set(font_scale=1.25)\n",
        "f, ax = plt.subplots(figsize=(15, 10))\n",
        "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOC11oEoyJnn",
        "colab_type": "text"
      },
      "source": [
        "OverallQual', 'GrLivArea' and 'TotalBsmtSF' are strongly correlated with 'SalePrice'. Check!\n",
        "'GarageCars' and 'GarageArea' are also some of the most strongly correlated variables. However, as we discussed in the last sub-point, the number of cars that fit into the garage is a consequence of the garage area. 'GarageCars' and 'GarageArea' are like twin brothers. You'll never be able to distinguish them. Therefore, we just need one of these variables in our analysis (we can keep 'GarageCars' since its correlation with 'SalePrice' is higher).\n",
        "'TotalBsmtSF' and '1stFloor' also seem to be twin brothers. We can keep 'TotalBsmtSF' just to say that our first guess was right (re-read 'So... What can we expect?').\n",
        "'FullBath'?? Really?\n",
        "'TotRmsAbvGrd' and 'GrLivArea', twin brothers again. Is this dataset from Chernobyl?\n",
        "Ah... 'YearBuilt'... It seems that 'YearBuilt' is slightly correlated with 'SalePrice'. Honestly, it scares me to think about 'YearBuilt' because I start feeling that we should do a little bit of time-series analysis to get this right. I'll leave this as a homework for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3XOyZcIyQGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scatterplot\n",
        "sns.set()\n",
        "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
        "sns.pairplot(df_train[cols], size = 2.5)\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_JRJQPKyjrf",
        "colab_type": "text"
      },
      "source": [
        "Although we already know some of the main figures, this mega scatter plot gives us a reasonable idea about variables relationships.\n",
        "\n",
        "One of the figures we may find interesting is the one between 'TotalBsmtSF' and 'GrLiveArea'. In this figure we can see the dots drawing a linear line, which almost acts like a border. It totally makes sense that the majority of the dots stay below that line. Basement areas can be equal to the above ground living area, but it is not expected a basement area bigger than the above ground living area (unless you're trying to buy a bunker).\n",
        "\n",
        "The plot concerning 'SalePrice' and 'YearBuilt' can also make us think. In the bottom of the 'dots cloud', we see what almost appears to be a shy exponential function (be creative). We can also see this same tendency in the upper limit of the 'dots cloud' (be even more creative). Also, notice how the set of dots regarding the last years tend to stay above this limit (I just wanted to say that prices are increasing faster now)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD7tnJ1njwRA",
        "colab_type": "text"
      },
      "source": [
        "**so here we must aware of the ouliers that should effect on saleprice**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIORq1-cj91G",
        "colab_type": "text"
      },
      "source": [
        "**outliers detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1htroeQ-kCQa",
        "colab_type": "text"
      },
      "source": [
        "**univariate analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgmnvE_elIyl",
        "colab_type": "text"
      },
      "source": [
        "we will see only the sales column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id9_7Bv6j9X3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#standardizing data\n",
        "saleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\n",
        "low_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\n",
        "high_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\n",
        "print('outer range (low) of the distribution:')\n",
        "print(low_range)\n",
        "print('\\nouter range (high) of the distribution:')\n",
        "print(high_range)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGjMi_f1lCtZ",
        "colab_type": "text"
      },
      "source": [
        "Low range values are similar and not too far from 0.\n",
        "\n",
        "High range values are far from 0 and the 7.something values are really out of range.\n",
        "\n",
        "For now, we'll not consider any of these values as an outlier but we should be careful with those two 7.something values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjYqw6SqlQsq",
        "colab_type": "text"
      },
      "source": [
        "**BIvariate analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbG8bwp7lCV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bivariate analysis saleprice/grlivarea\n",
        "var = 'GrLivArea'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFvcXJjIl8QJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   The two values with bigger 'GrLivArea' seem strange and they are not following \n",
        "the crowd. We can speculate why this is happening. Maybe they refer to agricultural area and that could explain the low price. I'm not sure about this but I'm quite confident that these two points are not representative of the typical case. Therefore, we'll define them as outliers and delete them.\n",
        "2. The two observations in the top of the plot are those 7.something observations that we said we should be careful about. They look like two special cases, however they seem to be following the trend. For that reason, we will keep them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5WZZFCilpOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.sort_values(by = 'GrLivArea', ascending = False)[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx-GGirGmYwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\n",
        "df_train = df_train.drop(df_train[df_train['Id'] == 524].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30iMGPlbmhh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bivariate analysis saleprice/grlivarea\n",
        "var = 'TotalBsmtSF'\n",
        "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
        "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLiXGVv1nJHP",
        "colab_type": "text"
      },
      "source": [
        "Total square feet of basement area We can feel tempted to eliminate some observations (e.g. TotalBsmtSF > 3000) but I suppose it's not worth it. We can live with that, so we'll not do anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1ChdFO1nueS",
        "colab_type": "text"
      },
      "source": [
        "**Now it's time to go deep and understand how 'SalePrice' complies with the statistical assumptions that enables us to apply multivariate techniques**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_oV7LGn6fG",
        "colab_type": "text"
      },
      "source": [
        "**NORMALITY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGpczLUDm0Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#histogram and normal probability plot\n",
        "sns.distplot(df_train['SalePrice'], fit=norm);\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(df_train['SalePrice'], plot=plt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFpqtILioSrx",
        "colab_type": "text"
      },
      "source": [
        "Ok, 'SalePrice' is not normal. It shows 'peakedness', positive skewness and does not follow the diagonal line.\n",
        "\n",
        "But everything's not lost. A simple data transformation can solve the problem. This is one of the awesome things you can learn in statistical books: in case of positive skewness, log transformations usually works well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nq6iFe0oAe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#applying log transformation\n",
        "df_train['SalePrice'] = np.log(df_train['SalePrice'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzEBtPwyoXdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transformed histogram and normal probability plot\n",
        "sns.distplot(df_train['SalePrice'], fit=norm);\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(df_train['SalePrice'], plot=plt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaQiq00tofLs",
        "colab_type": "text"
      },
      "source": [
        "**Done! Let's check what's going on with 'GrLivArea'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i15l2bVPoaBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#histogram and normal probability plot\n",
        "sns.distplot(df_train['GrLivArea'], fit=norm);\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(df_train['GrLivArea'], plot=plt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUZ4wL1Ooxiu",
        "colab_type": "text"
      },
      "source": [
        "It Look Like Some Skewness is there so we should apply the log transform  for this skewness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynYMgCZdoxDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#applying log transformation\n",
        "df_train['GrLivArea'] = np.log(df_train['GrLivArea'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmE_hMVPolyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#histogram and normal probability plot\n",
        "sns.distplot(df_train['GrLivArea'], fit=norm);\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(df_train['GrLivArea'], plot=plt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1MD2gNepfPP",
        "colab_type": "text"
      },
      "source": [
        "**Done! Let's check what's going on with 'TotalBsmtSF'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwAs0nB4pRBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(df_train['TotalBsmtSF'], fit=norm);\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(df_train['TotalBsmtSF'], plot=plt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jAholo7p5sJ",
        "colab_type": "text"
      },
      "source": [
        "Something that, in general, presents skewness.\n",
        "A significant number of observations with value zero (houses without basement).\n",
        "A big problem because the value zero doesn't allow us to do log transformations.\n",
        "To apply a log transformation here, we'll create a variable that can get the effect of having or not having basement (binary variable). Then, we'll do a log transformation to all the non-zero observations, ignoring those with value zero. This way we can transform data, without losing the effect of having or not basement.\n",
        "\n",
        "I'm not sure if this approach is correct. It just seemed right to me. That's what I call 'high risk engineering'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRYaF1wpntl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create column for new variable (one is enough because it's a binary categorical feature)\n",
        "#if area>0 it gets 1, for area==0 it gets 0\n",
        "df_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\n",
        "df_train['HasBsmt'] = 0 \n",
        "df_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI2uwPdtqGPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform data\n",
        "df_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bafxuSp8qIm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#histogram and normal probability plot\n",
        "sns.distplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], fit=norm);\n",
        "fig = plt.figure()\n",
        "res = stats.probplot(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], plot=plt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzx9YL3BqdIC",
        "colab_type": "text"
      },
      "source": [
        "**homoscedasticity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi7FxcfPqKoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scatter plot\n",
        "plt.scatter(df_train['GrLivArea'], df_train['SalePrice']);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWjP1UuGqx9m",
        "colab_type": "text"
      },
      "source": [
        "Older versions of this scatter plot (previous to log transformations), had a conic shape (go back and check 'Scatter plots between 'SalePrice' and correlated variables (move like Jagger style)'). As you can see, the current scatter plot doesn't have a conic shape anymore. That's the power of normality! Just by ensuring normality in some variables, we solved the homoscedasticity problem.\n",
        "\n",
        "Now let's check 'SalePrice' with 'TotalBsmtSF'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajmX3mWiqqFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scatter plot\n",
        "plt.scatter(df_train[df_train['TotalBsmtSF']>0]['TotalBsmtSF'], df_train[df_train['TotalBsmtSF']>0]['SalePrice']);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYBeTmhCq5e5",
        "colab_type": "text"
      },
      "source": [
        "We can say that, in general, 'SalePrice' exhibit equal levels of variance across the range of 'TotalBsmtSF'. Cool!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5teGW24rBVc",
        "colab_type": "text"
      },
      "source": [
        "**dummy variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN2xOPrFq35e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert categorical variable into dummy\n",
        "df_train = pd.get_dummies(df_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axCFddFarGIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-Icksmx8o0R",
        "colab_type": "text"
      },
      "source": [
        "**FEATURE ENGINEERING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOZKNm1k8vIQ",
        "colab_type": "text"
      },
      "source": [
        "Data Preparation\n",
        "\n",
        "Let's now prepare the data and build the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laC7qTyf8nxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lasso Regression\n",
        "# Split\n",
        "# Create matrix of all x features\n",
        "X = df_train.drop(['SalePrice'], axis = 1)\n",
        "# Create array of target variable\n",
        "y = df_train['SalePrice']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijIDsLCW9Stx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split training data into train and test sets\n",
        "from sklearn.model_selection import  train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.20,random_state=102)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRUY8Ox-mR3",
        "colab_type": "text"
      },
      "source": [
        "Model Building and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyuQ56o19B9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit\n",
        "# Import model\n",
        "from sklearn.linear_model import Lasso\n",
        "# Instantiate object\n",
        "lasso = Lasso()\n",
        "# Fit model to training data\n",
        "lasso = lasso.fit(X_train, y_train)\n",
        "# Predict\n",
        "y_pred_lasso = lasso.predict(X_test)\n",
        "# Score It\n",
        "from sklearn import metrics\n",
        "print('Linear Regression Performance')\n",
        "print('MAE',metrics.mean_absolute_error(y_test, y_pred_lasso))\n",
        "print('MSE',metrics.mean_squared_error(y_test, y_pred_lasso))\n",
        "print('RMSE',np.sqrt(metrics.mean_squared_error(y_test, y_pred_lasso)))\n",
        "print('R^2 =',metrics.explained_variance_score(y_test,y_pred_lasso))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-xoF_Bb-xwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lasso Coefficients\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "cdf = pd.DataFrame(data = lasso.coef_,index = X_train.columns, columns = ['Lasso Coefficients'])\n",
        "# **RANDOM FOREST**\n",
        "cdf.sort_values(by = 'Lasso Coefficients', ascending = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmS9qaZdBEPQ",
        "colab_type": "text"
      },
      "source": [
        "UNIVARIATE FEATURE SELECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi41NE_jA5_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select top 20% of features\n",
        "# Create matrix of x features\n",
        "X = df_train.drop(['SalePrice'],axis = 1)\n",
        "# Create array of target variable y\n",
        "y =df_train['SalePrice']\n",
        "# Feature Selector\n",
        "# Import\n",
        "from sklearn.feature_selection import SelectPercentile, f_regression\n",
        "# Instantiate object\n",
        "selector_f = SelectPercentile(f_regression, percentile=10)\n",
        "# Fit and transform\n",
        "x_best = selector_f.fit_transform(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2NiIB8BauP",
        "colab_type": "text"
      },
      "source": [
        "Pareto Approach\n",
        "\n",
        "In choosing the percentile cutoff, I took a Pareto 80/20 approach and selected the top 20% best, associated features. However, I'll review the F-score and p-values to confirm that 20% is an appropriate percentile to exclude a feature from participating in the learning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvZqtKGKBVKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "support = np.asarray(selector_f.get_support())\n",
        "\n",
        "# Supress displaying long numbers in scientific notation\n",
        "#pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "\n",
        "# Enable scientific notation\n",
        "pd.set_option('display.float_format', '{:.2e}'.format)\n",
        "\n",
        "# Column names of top 20%\n",
        "features = np.asarray(X.columns.values)\n",
        "features_with_support = features[support]\n",
        "# print('Top 20% of the best, associated features to SalePrice\\n',columns_with_support)\n",
        "# print('Number of Features:', len(columns_with_support))\n",
        "\n",
        "#f-scores of top 20%\n",
        "fscores = np.asarray(selector_f.scores_)\n",
        "fscores_with_support = fscores[support]\n",
        "\n",
        "# p-values of top 20%\n",
        "pvalues = np.asarray(selector_f.pvalues_)\n",
        "pvalues_with_support = pvalues[support]\n",
        "\n",
        "# Dataframe of top 20%\n",
        "top20 = pd.DataFrame({'F-score':fscores_with_support,\n",
        "                      'p-value':pvalues_with_support},\n",
        "                     index = features_with_support)\n",
        "# top20.index.name = 'Feature'\n",
        "print('Top 20% best associated features to SalePrice\\nNumber of features:',len(features_with_support))\n",
        "print(top20.sort_values(by = 'p-value', ascending = 'True'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f405TiDgB5K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_feat = df_train[features_with_support]\n",
        "corr =best_feat.corr() # We already examined SalePrice correlations\n",
        "plt.figure(figsize=(18, 12))\n",
        "\n",
        "sns.heatmap(corr[(corr >= 0.7) | (corr <= -0.7)], \n",
        "            cmap='coolwarm', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
        "            annot=True, annot_kws={\"size\": 8}, square=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ccOWL90CfK3",
        "colab_type": "text"
      },
      "source": [
        "Feature to Feature Correlation\n",
        "\n",
        "There are a few variables that are highly correlated (correlation >.80) with one another . The features representing redundant information and are less correlated with SalePrice can also be removed for further dimentionality reduction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aXirC0iCKeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Correlations to SalePrice\n",
        "from scipy import stats\n",
        "print('Correlation to SalePrice')\n",
        "print('GrLivArea:',stats.pearsonr(best_feat['GrLivArea'],df_train['SalePrice'])[0])\n",
        "print('TotRmsAbvGrd:',stats.pearsonr(best_feat['TotRmsAbvGrd'],df_train['SalePrice'])[0])\n",
        "print('--'*40)\n",
        "print('GarageCars:',stats.pearsonr(best_feat['GarageCars'],df_train['SalePrice'])[0])\n",
        "print('GarageArea:',stats.pearsonr(best_feat['GarageArea'],df_train['SalePrice'])[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pplmiNwyDvgQ",
        "colab_type": "text"
      },
      "source": [
        "Removing Duplicated Features\n",
        "\n",
        "GrLivArea vs TotRmsAbvGrd\n",
        "These features are highly correlated with a correlation of 0.83. Of these two variables, TotRmsAbvGrd will be removed because it has a lower correlation with SalePrice.\n",
        "\n",
        "Garage Cars vs Garage Area\n",
        "Garage Cars and GarageArea are also highly correlated as indicated by their correlation coefficient of 0.88. GarageArea will be removed as it has a lower correlation with our target variable, SalePrice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1EW8M6ADO2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove redundant features\n",
        "best_feat = best_feat.drop(['TotRmsAbvGrd','GarageArea'], axis = 1)\n",
        "best_feat.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5bA2A0_Dy8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forest Regression with Best Features\n",
        "# Split\n",
        "# Create matrix of best x features\n",
        "X_best = df_train[['OverallQual', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'TotalBsmtSF',\n",
        "       '1stFlrSF', 'GrLivArea', 'FullBath', 'Fireplaces', 'GarageCars',\n",
        "       'Neighborhood_NridgHt', 'ExterQual_Ex', 'ExterQual_Gd', 'ExterQual_TA',\n",
        "       'Foundation_PConc', 'HeatingQC_Ex', 'KitchenQual_Ex', 'KitchenQual_TA',\n",
        "       'SaleType_New', 'SaleCondition_Partial']]\n",
        "\n",
        "# Create array of target variable\n",
        "y = df_train['SalePrice']\n",
        "\n",
        "# Split training data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_best,y, test_size = .20,random_state = 102)\n",
        "\n",
        "# Fit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rforest = RandomForestRegressor(n_estimators = 300, random_state =102) \n",
        "rforest.fit(X_best,y)\n",
        "\n",
        "# Predict\n",
        "y_pred_rforest = rforest.predict(X_test)\n",
        "\n",
        "# Score It\n",
        "from sklearn import metrics\n",
        "print('Random Forest Regression Performance')\n",
        "print('MAE',metrics.mean_absolute_error(y_test, y_pred_rforest))\n",
        "print('MSE',metrics.mean_squared_error(y_test, y_pred_rforest))\n",
        "print('RMSE',np.sqrt(metrics.mean_squared_error(y_test, y_pred_rforest)))\n",
        "print('R^2 =',metrics.explained_variance_score(y_test,y_pred_rforest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woQGOY7gOEKL",
        "colab_type": "text"
      },
      "source": [
        "WITH TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qT6nvtPODY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load test data\n",
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/House Prices Advanced Regression Techniques/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjtO5DAjPClL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total=df_test.isnull().sum().sort_values(ascending=False)\n",
        "percentage=(df_test.isnull().sum()/df_test.isnull().count()).sort_values(ascending=False)\n",
        "missing_data=pd.concat([total,percentage],axis=1,keys=['total','percentage'])\n",
        "missing_data.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JxGN5LRdQQVR",
        "colab": {}
      },
      "source": [
        "df_test= df_test.drop((missing_data[missing_data['total'] >0]).index,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jz-ibvvfQQVT",
        "colab": {}
      },
      "source": [
        "total=df_test.isnull().sum().sort_values(ascending=False)\n",
        "percentage=(df_test.isnull().sum()/df_test.isnull().count()).sort_values(ascending=False)\n",
        "missing_data=pd.concat([total,percentage],axis=1,keys=['total','percentage'])\n",
        "missing_data.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh53LSqOUmM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert categorical variable into dummy\n",
        "df_test = pd.get_dummies(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCLH6G8ZVg8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create matrix of x features for training data\n",
        "X_train2 = df_train[['OverallQual', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'TotalBsmtSF',\n",
        "       '1stFlrSF', 'GrLivArea', 'FullBath', 'Fireplaces', 'GarageCars',\n",
        "       'Neighborhood_NridgHt', 'ExterQual_Ex', 'ExterQual_Gd', 'ExterQual_TA',\n",
        "       'Foundation_PConc', 'HeatingQC_Ex', 'KitchenQual_Ex', 'KitchenQual_TA',\n",
        "       'SaleType_New', 'SaleCondition_Partial']]\n",
        "\n",
        "# Create target variable array for training data\n",
        "y_train2 = df_train['SalePrice']\n",
        "\n",
        "# Create matrix of x features for test data\n",
        "X_test2 = df_train[['OverallQual', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'TotalBsmtSF',\n",
        "       '1stFlrSF', 'GrLivArea', 'FullBath', 'Fireplaces', 'GarageCars',\n",
        "       'Neighborhood_NridgHt', 'ExterQual_Ex', 'ExterQual_Gd', 'ExterQual_TA',\n",
        "       'Foundation_PConc', 'HeatingQC_Ex', 'KitchenQual_Ex', 'KitchenQual_TA',\n",
        "       'SaleType_New', 'SaleCondition_Partial']]\n",
        "\n",
        "# There is no target variable array for test data\n",
        "\n",
        "# Confirm data shapes\n",
        "print('Data Shapes')\n",
        "print('x_train shape', X_train2.shape)\n",
        "print('y_train shape',y_train2.shape)\n",
        "print('x_test shape', X_test2.shape)\n",
        "\n",
        "# Fit Random Forest to training data\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rforest = RandomForestRegressor(n_estimators = 300, random_state = 0) \n",
        "rforest.fit(X_train2,y_train2)\n",
        "\n",
        "# Predict using test data\n",
        "y_pred_rforest2 = rforest.predict(X_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVv3vCEUWGFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame({\"Id\": df_test[\"Id\"],\"SalePrice\": y_pred_rforest2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJlK2FU7WSd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKRn1jmTl5z7",
        "colab_type": "text"
      },
      "source": [
        "**SO HERE WE PERDICT THE HOUSE PRICE AS PER THE HOUSE PERSQUARE YARD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8gi4rqlW6yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('HousingSubmissionbb.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}